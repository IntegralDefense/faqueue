[general]
working_dir = /home/user/dev/faqueue/working/
logging_dir = /home/user/dev/faqueue/log/
update_minutes = 10
# Modules to load and run (use a comma separated list)
load_modules = carbonblack,yarastrings,splunk,autoanalyzed
# URL to submit to ACE.
ace_submit = http://ace.local:5001/submit_alert

[proxy]
http_proxy = 
https_proxy = 

[database]
# CRITs mongodb host
host = localhost
port = 27017

[module_yarastrings]
module_name = yara_strings
class_name = YaraStrings
sleep_time = 300
scan_count = 80000
results_limit = 20

[module_carbonblack]
module_name = carbon_black
class_name = CarbonBlack
url = https://carbonblack-server.local:8443
token = <TOKEN HERE>
time_range = 15
results_limit = 10

[module_splunk]
module_name = splunk
class_name = Splunk
username = api_user
password = APITIEM
splunk_server = https://splunk.local:8089
splunk_hostname = https://splunk.local
splunk_port = 8089
splunk_rest_search_endpoint = /servicesNS/admin/search/search/jobs/export
results_limit = 10

[module_ssdeep]
module_name = ssdeep
class_name = SSDeep
scan_count = 20000
# 0 - 100
match_threshold = 20

[module_autoanalyzed]
module_name = auto_analyzed
class_name = AutoAnalyzed

[module_email]
module_name = email
class_name = Email
# The location of the email archives
email_dir = /opt/emails/raw/
# The number of emails to scan
email_count = 2000
# The passphrase used to decrypt the emails
gpg_passphrase = PASSWORDLOL

[module_html_js_cache]
module_name = html_js_cache
class_name = HtmlJsCache
html_cache = /opt/splunk_url_downloader/data/html
js_cache = /opt/splunk_url_downloader/data/js
